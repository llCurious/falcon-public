{"cells":[{"cell_type":"code","execution_count":76,"metadata":{"colab":{},"colab_type":"code","id":"NyFvxvSgsTqQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-uJEFsv4tBBY"},"source":["## Lets get the data, model and setup trainnig code"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{},"colab_type":"code","id":"KaC8fIULs7XK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images 60000, Test images 10000\n"]}],"source":["train_loader = DataLoader(datasets.MNIST(\"./data\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n","test_loader = DataLoader(datasets.MNIST(\"./data\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n","\n","print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{},"colab_type":"code","id":"JRKHX6Ssp2Hz"},"outputs":[],"source":["class mnist_model(nn.Module):\n","  def __init__(self):\n","    super(mnist_model, self).__init__()\n","    self.layer1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=0)\n","    self.layer2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=0)\n","    self.layer3 = nn.Linear(800, 500, bias=True)\n","    self.layer4 = nn.Linear(500, 10, bias=True)\n","\n","    self.act = nn.ReLU()\n","    self.pool = nn.MaxPool2d((2, 2))\n","\n","  def forward(self, x):\n","    out = self.act(self.layer1(x))\n","    out = self.pool(out)\n","    out = self.act(self.layer2(out))\n","    out = self.pool(out)\n","    out = out.view(-1, 800)\n","    out = self.act(self.layer3(out))\n","    # out = self.act(self.layer4(out))\n","    out = self.layer4(out)\n","    return out\n","\n","  def output(self, x):\n","    out1 = self.act(self.layer1(x))\n","    out1 = self.pool(out1)\n","    out2 = self.act(self.layer2(out1))\n","    out2 = self.pool(out2)\n","    out2 = out2.view(-1, 800)\n","    out3 = self.act(self.layer3(out2))\n","    out4 = self.act(self.layer4(out3))    \n","    return out1, out2, out3, out4"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{},"colab_type":"code","id":"Suh22BC9tMTj"},"outputs":[{"name":"stdout","output_type":"stream","text":["mnist_model(\n","  (layer1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (layer2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n","  (layer3): Linear(in_features=800, out_features=500, bias=True)\n","  (layer4): Linear(in_features=500, out_features=10, bias=True)\n","  (act): ReLU()\n","  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",")\n"]}],"source":["model = mnist_model()\n","print(model)\n","\n","epochs = 0\n","lr = 0.1\n","\n","USE_MSE = False\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","criterion = nn.MSELoss() if USE_MSE else nn.CrossEntropyLoss()\n","# criterion = nn.MSELoss()\n","# lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["mnist_model(\n","  (layer1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","  (layer2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n","  (layer3): Linear(in_features=800, out_features=500, bias=True)\n","  (layer4): Linear(in_features=500, out_features=10, bias=True)\n","  (act): ReLU()\n","  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",")"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","# GPU run\n","gpu_list = [0, 1, 2, 3]\n","gpu_list_str = ','.join(map(str, gpu_list))\n","os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", gpu_list_str)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","torch.nn.DataParallel(model)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ztvyum2f-XqU"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","## Training"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{},"colab_type":"code","id":"pOYNVw8B-aKz"},"outputs":[],"source":["def get_acc(model, loader):\n","  correct = 0\n","  total = 0\n","  for img, label in loader:\n","    correct += torch.sum(torch.argmax(model(img.to(device)), -1) == label.to(device)).item()\n","    total += len(img)\n","  return 100*correct/total"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{},"colab_type":"code","id":"Yk0nHkbhtPkz"},"outputs":[],"source":["for e in range(epochs):\n","  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n","  for img, label in train_loader:\n","    # print(img.shape, label.shape)\n","    label_onehot = nn.functional.one_hot(label.to(device), num_classes=10).float()\n","    out = model(img.to(device))\n","    optimizer.zero_grad()\n","    loss = criterion(out, label_onehot)\n","    loss.backward()\n","    optimizer.step()\n","  # lrs.step()\n","  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QsQBF-eWFDY7"},"source":["## Extract weights"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{},"colab_type":"code","id":"CdQe9RA0vthi"},"outputs":[],"source":["params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{},"colab_type":"code","id":"DO_6VdePwxF_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Layer layer1, type weight, shape (20, 1, 5, 5)\n","Layer layer1, type bias, shape (20,)\n","Layer layer2, type weight, shape (50, 20, 5, 5)\n","Layer layer2, type bias, shape (50,)\n","Layer layer3, type weight, shape (500, 800)\n","Layer layer3, type bias, shape (500,)\n","Layer layer4, type weight, shape (10, 500)\n","Layer layer4, type bias, shape (10,)\n"]}],"source":["for (name, p) in params:\n","  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{},"colab_type":"code","id":"Lypaj9GkFrUU"},"outputs":[],"source":["#print(params)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IcatFuNhe1fY"},"source":["## Visualize hidden activations"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{},"colab_type":"code","id":"r6lxIEFReMxL"},"outputs":[],"source":["# print(model.children())\n","# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{},"colab_type":"code","id":"4rd-AKLbeL-A"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","\n","# for _ in range(out.shape[1]):\n","#   plt.figure(figsize=(1, 1))\n","#   plt.imshow(out[0, 0], cmap=\"gray\")"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{},"colab_type":"code","id":"VVz78PBcFzka"},"outputs":[],"source":["for img, label in train_loader:\n","  break"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{},"colab_type":"code","id":"ACfBKOB3v7Dm"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# path = \"/content/drive/My Drive/Colab Notebooks/Falcon Neural Network/LeNet/\""]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{},"colab_type":"code","id":"eiqkXaaBZUci"},"outputs":[{"name":"stdout","output_type":"stream","text":["Save parameters to /home/haoqi.whq/output/init/LeNet/\n"]}],"source":["import os\n","subdir = 'trained' if epochs != 0 else 'init'\n","path = f\"{os.path.expanduser('~')}/output/{subdir}/LeNet/\"\n","if not os.path.exists(path):\n","    os.makedirs(path)\n","\n","print(f'Save parameters to {path}')\n","\n","np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n","np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].data.cpu().view(-1))\n","np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n","np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n","np.savetxt(fname=path+\"outputlayer4_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[3].tolist())\n","\n","np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(5*5*1, 20).tolist())\n","np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n","np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].reshape(5*5*20, 50).tolist())\n","np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n","np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n","np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())\n","np.savetxt(fname=path+\"weight4_0\", delimiter=\" \", X=params[6][1].tolist())\n","np.savetxt(fname=path+\"bias4_0\", delimiter=\" \", X=params[7][1].tolist())"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"MNIST_LeNet.ipynb","provenance":[{"file_id":"1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl","timestamp":1597179603592}]},"kernelspec":{"display_name":"falcon","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"de2997ba25086c1e82cd70d564ea0c2d9f27788cf106070172defeb4a05974d8"}}},"nbformat":4,"nbformat_minor":0}
