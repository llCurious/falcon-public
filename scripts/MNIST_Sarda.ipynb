{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"NyFvxvSgsTqQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-uJEFsv4tBBY"},"source":["## Lets get the data, model and setup training code"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","id":"KaC8fIULs7XK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images 60000, Test images 10000\n"]}],"source":["train_loader = DataLoader(datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=True)\n","test_loader = DataLoader(datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True), batch_size=128, shuffle=False)\n","\n","print(f\"Training images {len(train_loader.dataset)}, Test images {len(test_loader.dataset)}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"JRKHX6Ssp2Hz"},"outputs":[],"source":["class mnist_model(nn.Module):\n","  def __init__(self):\n","    super(mnist_model, self).__init__()\n","    self.layer1 = nn.Conv2d(1, 5, kernel_size=2, stride=2, padding=0)\n","    self.layer2 = nn.Linear(980, 100, bias=True)\n","    self.layer3 = nn.Linear(100, 10, bias=True)\n","    self.act = nn.ReLU()\n","\n","  def forward(self, x):\n","    out = self.act(self.layer1(x))\n","    out = out.view(-1, 980)\n","    out = self.act(self.layer2(out))\n","    out = self.layer3(out)\n","    return out\n","\n","  def output(self, x):\n","    out1 = self.act(self.layer1(x))\n","    out1 = out1.view(-1, 980)\n","    out2 = self.act(self.layer2(out1))\n","    out3 = self.layer3(out2)\n","    return out1, out2, out3"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{},"colab_type":"code","id":"Suh22BC9tMTj"},"outputs":[{"name":"stdout","output_type":"stream","text":["mnist_model(\n","  (layer1): Conv2d(1, 5, kernel_size=(2, 2), stride=(2, 2))\n","  (layer2): Linear(in_features=980, out_features=100, bias=True)\n","  (layer3): Linear(in_features=100, out_features=10, bias=True)\n","  (act): ReLU()\n",")\n"]}],"source":["model = mnist_model()\n","print(model)\n","\n","epochs = 15\n","lr = 0.1\n","\n","USE_MSE = False\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","criterion = nn.MSELoss() if USE_MSE else nn.CrossEntropyLoss()\n","lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ztvyum2f-XqU"},"source":["## Training"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"pOYNVw8B-aKz"},"outputs":[],"source":["def get_acc(model, loader):\n","  correct = 0\n","  total = 0\n","  for img, label in loader:\n","    correct += torch.sum(torch.argmax(model(img), -1) == label).item()\n","    total += len(img)\n","  return 100*correct/total"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","id":"Yk0nHkbhtPkz"},"outputs":[{"name":"stdout","output_type":"stream","text":["lr 0.1\n","Epoch 0, training accuracy 93.02, test accuracy 93.27\n","lr 0.09890738003669029\n","Epoch 1, training accuracy 95.65666666666667, test accuracy 95.84\n","lr 0.09567727288213004\n","Epoch 2, training accuracy 96.67, test accuracy 96.49\n","lr 0.09045084971874738\n","Epoch 3, training accuracy 97.29, test accuracy 97.21\n","lr 0.08345653031794292\n","Epoch 4, training accuracy 97.71666666666667, test accuracy 97.21\n","lr 0.07500000000000001\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-907c270a4486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print(img.shape, label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlabel_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-3c1d45abae44>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m980\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for e in range(epochs):\n","  print(\"lr\", optimizer.param_groups[0][\"lr\"])\n","  for img, label in train_loader:\n","    # print(img.shape, label.shape)\n","    out = model(img)\n","    label_onehot = nn.functional.one_hot(label, num_classes=10).float()\n","    # print(out.shape)\n","    optimizer.zero_grad()\n","    loss = criterion(out, label_onehot)\n","    loss.backward()\n","    optimizer.step()\n","  lrs.step()\n","  print(f\"Epoch {e}, training accuracy {get_acc(model, train_loader)}, test accuracy {get_acc(model, test_loader)}\")"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QsQBF-eWFDY7"},"source":["## Extract weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"CdQe9RA0vthi"},"outputs":[],"source":["params = [(name, p.data.cpu().numpy()) for (name, p) in model.named_parameters()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"DO_6VdePwxF_"},"outputs":[],"source":["for (name, p) in params:\n","  print(f\"Layer {name.split('.')[0]}, type {name.split('.')[1]}, shape {p.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Lypaj9GkFrUU"},"outputs":[],"source":["#print(params)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IcatFuNhe1fY"},"source":["## Visualize hidden activations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"r6lxIEFReMxL"},"outputs":[],"source":["# print(model.children())\n","# out = list(model.children())[0](img.cuda()).data.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"4rd-AKLbeL-A"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","\n","# for _ in range(out.shape[1]):\n","#   plt.figure(figsize=(1, 1))\n","#   plt.imshow(out[0, 0], cmap=\"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"VVz78PBcFzka"},"outputs":[],"source":["for img, label in train_loader:\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ACfBKOB3v7Dm"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = \"/content/drive/My Drive/Colab Notebooks/Falcon Neural Network/Sarda/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eiqkXaaBZUci"},"outputs":[],"source":["import os\n","\n","np.savetxt(fname=path+\"input_0\", delimiter=\" \", X=img.cuda().view(-1, 784).tolist())\n","np.savetxt(fname=path+\"outputlayer1_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[0].tolist())\n","np.savetxt(fname=path+\"outputlayer2_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[1].tolist())\n","np.savetxt(fname=path+\"outputlayer3_0\", delimiter=\" \", X=model.output(img.cuda().view(128, 1, 28, 28))[2].tolist())\n","\n","np.savetxt(fname=path+\"weight1_0\", delimiter=\" \", X=params[0][1].reshape(2*2*1, 5).tolist())\n","np.savetxt(fname=path+\"bias1_0\", delimiter=\" \", X=params[1][1].tolist())\n","np.savetxt(fname=path+\"weight2_0\", delimiter=\" \", X=params[2][1].tolist())\n","np.savetxt(fname=path+\"bias2_0\", delimiter=\" \", X=params[3][1].tolist())\n","np.savetxt(fname=path+\"weight3_0\", delimiter=\" \", X=params[4][1].tolist())\n","np.savetxt(fname=path+\"bias3_0\", delimiter=\" \", X=params[5][1].tolist())"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"MNIST_Sarda.ipynb","provenance":[{"file_id":"1G0aq7Vn-bomx5TTWCkUXm2iAPtQjYxxl","timestamp":1597179603592}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
