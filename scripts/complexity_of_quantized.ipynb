{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "# import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SecureML\n",
    "def BasicNN():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(28,28,1)))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def MiniONN():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16,(5,5),strides=(1,1),input_shape=(28,28,1), padding='valid',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(16,(5,5),strides=(1,1),input_shape=(12,12,16), padding='valid',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten()) # 16x4x4\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def LeNet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(20,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(50,(5,5),strides=(1,1),padding='valid',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def AlexNet():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(227,227,3),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def VGG16():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), strides = (1,1), input_shape = (224,224,3), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(64,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(128,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(256,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(512,(3,3), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dense(1000, activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/whq/anaconda3/envs/tfe/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "[conv2d](None, 28, 28, 1), (None, 24, 24, 16)\n",
      "[max_pooling2d](None, 24, 24, 16), (None, 12, 12, 16)\n",
      "[conv2d_1](None, 12, 12, 16), (None, 8, 8, 16)\n",
      "[max_pooling2d_1](None, 8, 8, 16), (None, 4, 4, 16)\n",
      "[flatten](None, 4, 4, 16), (None, 256)\n",
      "[dense](None, 256), (None, 100)\n",
      "[dense_1](None, 100), (None, 10)\n"
     ]
    }
   ],
   "source": [
    "model = MiniONN()\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(\"[{0}]{1}, {2}\".format(str(layer.name), str(layer.input_shape), str(layer.output_shape)))\n",
    "\n",
    "    shape = (layer.output_shape, layer.input_shape)\n",
    "    # print(shape)\n",
    "\n",
    "# input shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (10, 5308416), After: (11, 11796480)\n",
      "[conv2d_17](None, 224, 224, 3), (None, 224, 224, 64)\n",
      "------Handle convolution\n",
      "[conv2d_18](None, 224, 224, 64), (None, 224, 224, 64)\n",
      "------Handle convolution\n",
      "[max_pooling2d_9](None, 224, 224, 64), (None, 112, 112, 64)\n",
      "------Handle max pooling\n",
      "[conv2d_19](None, 112, 112, 64), (None, 112, 112, 128)\n",
      "------Handle convolution\n",
      "[conv2d_20](None, 112, 112, 128), (None, 112, 112, 128)\n",
      "------Handle convolution\n",
      "[max_pooling2d_10](None, 112, 112, 128), (None, 56, 56, 128)\n",
      "------Handle max pooling\n",
      "[conv2d_21](None, 56, 56, 128), (None, 56, 56, 256)\n",
      "------Handle convolution\n",
      "[conv2d_22](None, 56, 56, 256), (None, 56, 56, 256)\n",
      "------Handle convolution\n",
      "[conv2d_23](None, 56, 56, 256), (None, 56, 56, 256)\n",
      "------Handle convolution\n",
      "[max_pooling2d_11](None, 56, 56, 256), (None, 28, 28, 256)\n",
      "------Handle max pooling\n",
      "[conv2d_24](None, 28, 28, 256), (None, 28, 28, 512)\n",
      "------Handle convolution\n",
      "[conv2d_25](None, 28, 28, 512), (None, 28, 28, 512)\n",
      "------Handle convolution\n",
      "[conv2d_26](None, 28, 28, 512), (None, 28, 28, 512)\n",
      "------Handle convolution\n",
      "[max_pooling2d_12](None, 28, 28, 512), (None, 14, 14, 512)\n",
      "------Handle max pooling\n",
      "[conv2d_27](None, 14, 14, 512), (None, 14, 14, 512)\n",
      "------Handle convolution\n",
      "[conv2d_28](None, 14, 14, 512), (None, 14, 14, 512)\n",
      "------Handle convolution\n",
      "[conv2d_29](None, 14, 14, 512), (None, 14, 14, 512)\n",
      "------Handle convolution\n",
      "[max_pooling2d_13](None, 14, 14, 512), (None, 7, 7, 512)\n",
      "------Handle max pooling\n",
      "[flatten_3](None, 7, 7, 512), (None, 25088)\n",
      "[dense_7](None, 25088), (None, 4096)\n",
      "------Handle Dense\n",
      "[dense_8](None, 4096), (None, 4096)\n",
      "------Handle Dense\n",
      "[dense_9](None, 4096), (None, 1000)\n",
      "------Handle Dense\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAD4CAYAAABfYrnHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfEElEQVR4nO3de7xVVb338c9XkDC8gJc4CCiU6BEIvHDRVFIy8FKaFiKnEi3FesrHHs85aZfXAdNer3o0K089drBILC+piYlpapqXSlO8JRdTCkzwgoIXNhdlw+/5Y47NXhv33ixg3eZa3/frNV9rzrHmmHPsPeeevz3HHHMMRQRmZmZ5sF21C2BmZlYsBy0zM8sNBy0zM8sNBy0zM8sNBy0zM8uNrtUuQDG222672GGHHapdDDOzXFm9enVERF3dnOQiaO2www6sWrWq2sUwM8sVSWuqXYZSq6sIbGZm9c1By8zMcsNBy8zMciMXz7Tas27dOpYsWcLatWurXZSy6d69O/369WP77bevdlHMyqIR/o4roZGuFcpD34M9evSITRtiLFq0iJ122onddtsNSVUqWflEBMuXL2flypUMHDiw2sUxK4t6/zuuhM6uFZJWR0SPKhWtLHJbPbh27dq6PtElsdtuu/k/UKtr9f53XAmNdq3IbdAC6v5Er/efzwx8npdCI/0Ocx20zMyssdRP0JJKO5XYT37yE66++uqSb9esntT4n3FRFi9ezNChQ8uy7QEDBvDaa6+VZdt5kdvWg3nzhS98odpFAKr3h1yLaqYNUiMflDvugDaNrEZUrSilEBFs2LCh2sWoa/Vzp1UFF110Efvttx+HH344kyZN4tJLL+XKK69k5MiRDB8+nE9+8pOsXr0agGnTpnHppZcCcOSRR3L++eczatQo9t13Xx588MFq/hhmDe2yyy5j6NChDB06lB/84AdccMEF/PjHP974feHf7iWXXMLIkSMZNmwYU6dOBbI7q/3224/TTjuNoUOH8sILL7B+/XrOOusshgwZwrhx41izJutN6e9//zvHHHMMBx98MEcccQTPPPMMALNnz2b06NEceOCBHH300bzyyisALF++nHHjxjFkyBDOPPNM8tDau+wiouan9773vbGp+fPnt03I/nEu3bQZjzzySAwfPjzWrFkTb731Vuyzzz5xySWXxGuvvbZxnW984xtx+eWXR0TE1KlT45JLLomIiA9/+MNx3nnnRUTEb3/72/jIRz7S4X7e9XNuo1L/mvI81Yxq/yKqOM2/446IRx/dOFX6GM+ZMyeGDh0aTU1NsXLlyhg8eHA8/vjjMWbMmI3r7L///vHPf/4z7rzzzjjrrLNiw4YNsX79+jj++OPj/vvvj0WLFoWkeOihhyIiYtGiRdGlS5d44oknIiJiwoQJ8Ytf/CIiIsaOHRvPPvtsREQ8/PDDcdRRR0VExIoVK2LDhg0REXHllVduvD6cc845ceGFF0ZExG233RZAvPrqq+3+LO1dK4BVEdW/hpdycvXgVvrTn/7EiSeeSPfu3enevTsf//jHAZg7dy7f/OY3eeONN2hqamL8+PHt5j/55JMBOPjgg1m8eHGlim1mBf74xz9y0kkn0aNH9irTySefzIMPPsiyZct48cUXefXVV+nVqxf9+/fnhz/8IXfddRcHHnggAE1NTTz33HPstdde7L333hxyyCEbtztw4EAOOOAAoPVvvKmpiT//+c9MmDBh43pvv/02AEuWLGHixIm89NJLvPPOOxvft3rggQe4+eabATj++OPp1atX2X8ntc5Bq8ROP/10brnlFoYPH85VV13Ffffd1+5673nPewDo0qULzc3NFSyhmW3OhAkTuOmmm3j55ZeZOHEiABHB1772Nc4+++w26y5evHhj0GvR8vcN2d/4mjVr2LBhAz179uTJJ5981/7OOecczjvvPE444QTuu+8+pk2bVvKfqV74mdZWOuyww5g9ezZr166lqamJ2267DYCVK1fSp08f1q1bxzXXXFPlUppZZ4444ghuueUWVq9ezapVq5g1axZHHHEEEydO5Prrr+emm27aeGc0fvx4ZsyYQVNTEwBLly5l2bJlRe9r5513ZuDAgdx4441AFgSfeuopAN5880369u0LwMyZMzfmGTNmDNdeey0Ad9xxB6+//vq2/9A5V9Y7LUk9gZ8CQ4EAPgf8DfgVMABYDJwSEdt+JCK2eRNbYuTIkZxwwgkMGzaM3r1788EPfpBddtmFiy66iNGjR7PHHnswevRoVq5cWdFymeVZPDoHRlSuBeFBBx3E6aefzqhRowA488wzN1b/rVy5kr59+9KnTx8Axo0bx4IFCzj00EMB2HHHHfnlL39Jly5dit7fNddcwxe/+EUuvvhi1q1bx6mnnsrw4cOZNm0aEyZMoFevXowdO5ZFixYBMHXqVCZNmsSQIUP40Ic+xF577VXKHz+Xytr3oKSZwIMR8VNJ3YD3Al8HVkTEdyRdAPSKiPM72057fQ8uWLCA/fffv1xFL0pTUxM77rgjq1evZsyYMUyfPp2DDjqopPso9c/ZyK2rN1Xh/3M61sAHZcEdd7D/7ru3Taxg0Kon7V0r6rHvwbLdaUnaBRgDnA4QEe8A70g6ETgyrTYTuA/oNGjVqilTpjB//nzWrl3L5MmTSx6wzMysrXJWDw4EXgV+Lmk48BhwLtA7Il5K67wM9C5jGcqqpa7ZzMwqo5wNMboCBwFXRMSBwCrggsIV0nsE7VbSSJoiaY6kOR21ritn1WYtqPefz4wNG9q/ANgWaaRrRTmD1hJgSUT8JS3fRBbEXpHUByB9ttv8JiKmR8SIiBjRteu7bwi7d+/O8uXL6/ZgRWRj5HTv3r3aRTErm+4LF7K8udmBaxs02rWi3A0xHgTOjIi/SZoGtDwQXF7QEGPXiPhqZ9tpryFGI4x4Wo7RSBv4mf+71Mz/Ow18UNb16sWSadNYu88+sF36H3rvvatbqBzq6FpRjw0xyh20DiBr8t4N+AdwBtnd3Q3AXsDzZE3eV3S2nfaClm2dBr4+vouDVo2qmQOTfw5aVeKgVTq+PraqmVPfB6Wtmjkw+VePQcs9YpiZNSBJ/SX9QdJ8SfMknZvSp0laKunJNB1XkOdrkhZK+puk8QXpx6S0hemxT/nK7TutxuJ/6lvVzKnvg9JWzRyY/OvsTis1hOsTEY9L2onstaRPAKcATRFx6SbrDwauA0YBewK/B/ZNXz8LfJSsAd6jwKSImF/6n8gd5pqZNaT0vuxLaX6lpAVA306ynAhcHxFvA4skLSQLYAALI+IfAJKuT+uWJWi5etDMrH51bXnfNU1T2ltJ0gDgQKDlFaUvS/qrpBmSWsZD6Qu8UJBtSUrrKL0sHLTMzOpXc8v7rmmavukKknYEfg18JSLeAq4APgAcQHYn9r1KFnhzXD1oZtagJG1PFrCuiYibASLilYLvrwRuS4tLgf4F2fulNDpJLznfaZmZNSBJAn4GLIiIywrS+xSsdhIwN83fCpwq6T2SBgKDgEfIGl4MkjQwjeZxalq3LHynZWbWmA4DPgs8LenJlPZ1YFLqGCLIxjw8GyAi5km6gayBRTPwpYhYDyDpy8CdQBdgRkTMK1eh3eS9wbh1dauaOfV9UNqqmQOTf3652MzMrIoctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDcctMzMLDfKOgikpMXASmA90BwRIyTtCvwKGEA2wNgpEfF6OcthZmb1oRJ3WkdFxAERMSItXwDcExGDgHvSspmZ2WZVo3rwRGBmmp8JfKIKZTAzsxwqd9AK4C5Jj0maktJ6R8RLaf5loHd7GSVNkTRH0pzm5uYyF9PMzPKgrM+0gMMjYqmk9wF3S3qm8MuICEnRXsaImA5MB+jRo0e765iZWWMp651WRCxNn8uAWcAo4BVJfQDS57JylsHMzOpH2YKWpB6SdmqZB8YBc4FbgclptcnAb8pVBjMzqy/lrB7sDcyS1LKfayPid5IeBW6Q9HngeeCUMpbBzMzqiCJq/3FRjx49YtWqVdUuRl3I/ocwgJo59X1Q2qqZA5N/klZHRI9ql6OU3COGmZnlhoOWmZnlhoOWmZnlhoOWmZnlhoOWmZnlhoOWmVkDktRf0h8kzZc0T9K5KX1XSXdLei599krpknS5pIWS/irpoIJtTU7rPydpckf7LAUHLTOzxtQM/HtEDAYOAb4kaTAdj8RxLDAoTVOAKyALcsBUYDRZr0dTWwJdOThomZk1oIh4KSIeT/MrgQVAXzoeieNE4OrIPAz0TF3xjQfujogVaWzEu4FjylXucneYa2Zm1dNV0pyC5empM/I2JA0ADgT+QscjcfQFXijItiSldZReFg5aZmb1q7lgAN52SdoR+DXwlYh4SwU9tHQ2Eke1uHrQzKxBSdqeLGBdExE3p+SORuJYCvQvyN4vpXWUXhYOWmZmDUjZLdXPgAURcVnBVx2NxHErcFpqRXgI8GaqRrwTGCepV2qAMS6llYWrB83MGtNhwGeBpyU9mdK+DnyH9kfiuB04DlgIrAbOAIiIFZIuAh5N630rIlaUq9Du5b3BuEPxVjVz6vugtFUzByb/3Mu7mZlZFTlomZlZbjhomZlZbjhomZlZbjhomZlZbjhomZlZbjhomZlZbjhomZlZbjhomZlZbrgbJzMzqxhJ2wHDgT2BNcDciFjWea5WZQ9akroAc4ClEfExSQOB64HdgMeAz0bEO+Uuh5mZVY+kDwDnA0cDzwGvAt2BfSWtBv4HmBkRGzrbTiWqB88lGxGzxXeB70fEPsDrwOcrUAYzM6uui4FfAh+IiPER8ZmI+FREDANOAHYh68C3U2XtMFdSP7Lhmr8NnAd8nCy6/ktENEs6FJgWEeM72447zC0d983aqmb6ZfVBaatmDkz+1WOHueWuHvwB8FVgp7S8G/BGRDSn5Q6HZZY0BZgC0K1bt/KW0szMyk7S3sCqiHgtjcl1OPD3iJhV7DbKVj0o6WPAsoh4bGvyR8T0iBgRESO6dnV7ETOzPJP0X8C9wMOSLia7qdkd+N+SflDsdsoZDQ4DTpB0HNnDtp2BHwI9JXVNd1tlHZbZzMxqxqnA/sB7gX+SPSZaLakr8GSxGynbnVZEfC0i+kXEALLC3hsRnwb+AHwqrVY4lLOZmdWvtRHxTkS8QVYluBog3cAU3YK8GvVu5wPXp9vDJ4CfVaEMZmZWWT0lnQwI2DnNk5Z3KXYjZW09WCpuPVg6bqjWqmZOfR+UtmrmwORfLbUelPTzzr6PiDOK2Y5bOJiZWdkVG5Q2x0HLzMzKTtJ5nX0fEZcVsx0HLTMzq4RLyVoJ3gG8TfYsa4s5aJmZWSUcCEwCjifrd/Y64J7YwoYVbojRYPzMv1XNnPo+KG3VzIHJv1pqiFFI0ofIAtjRwPkRcWuxeTu905K0a2ffR8SKYndkZmYmaQ+yu64PknXlV/SwJLD56sHHgCCre9yLrFd2AT3J3mgeuGXFNTOzRiTpc8ApZD0k3QScsiXjaG3cTjHVg5KuBGZFxO1p+VjgExFx9pbucGu4erB0XBPVqmZqoXxQ2qqZA5N/tVQ9KGkDMBd4PiW1OdARcUIx2ym2IcYhEXFWwcbvkPR/i8xrZmZ2VCk2UmzQelHSN8kG8AL4NPBiKQpgZmb1LyLuL8V2iu0wdxKwBzArTe9LaWZmllOSZkhaJmluQdo0SUslPZmm4wq++5qkhZL+Jml8QfoxKW2hpAs62NdsSR+XtH07371f0rfSc6/Oy+wm743Fj09a1cyp74PSVs0cmPzb3DMtSWOAJuDqiBia0qYBTRFx6SbrDiZ7t2oUsCfwe2Df9PWzwEfJWgM+CkyKiPmb5P8XshHsPwmsIBvFvjswAPg78KOI2OyoH0VVD0raF/iPtPGNeSJibDH5zcys9kTEA5IGFLn6icD1EfE2sEjSQrIABrAwIv4BIOn6tG6boBURL5ONZP/VtM8+wBrg2ZZhSopR7DOtG4GfAD8F1he7cTMzq6qukuYULE+PiOlF5PuypNOAOcC/R8TrQF/g4YJ1lqQ0gBc2SR/d2cYjYjGwuIhyvEuxQas5Iq7Ymh2YmVnVNEfEiC3McwVwEVmT9IuA7wGbfdZUKcU2xJgt6X9J6iNp15aprCUzM7OKi4hXImJ9RGwArqS1CnAp0L9g1X4praP0sij2Tmty+vzPgrQA3l/a4piZWTVJ6hMRL6XFk8heCAa4FbhW0mVkDTEGAY+Q9ZI0SNJAsmB1KvBv5SpfUUErItxdk5lZnZF0HXAksLukJcBU4EhJB5DdmCwGzgaIiHmSbiBrYNEMfCki1qftfBm4E+gCzIiIeZ3s82Nk1Y57k8UgZZuPnYsqc5HdOJ3WXnpEXF3MTraVm7yXjltXt6qZltU+KG3VzIHJv1rqxqlFanV4MvD0lg5LAsVXD44smO8OfAR4HKhI0DIzs7rxAjB3awIWFF89eE7hsqSewPVbs0MzM2toXwVul3Q/2QjGAETEZcVk3tqRi1fhYUnMzGzLfZusF47uQLctzVxsjxizae1GvguwP3DDlu7MzMwa3p4tXUZtjWLvtAr7oGoGno+IJVu7UzMza1i3SxoXEXdtTeaiXi5OXco/A+wE9ALe2VweSd0lPSLpKUnzJF2Y0gdK+kvqDfhXkrb49tDMzHLri8DvJK2R9JaklZLeKjZzUUFL0ilkL5FNIBsu+S+SPrWZbG8DYyNiOHAAcIykQ4DvAt+PiH2A14HPF1tYMzPLt4jYKSK2i4gdImLntFzUO1pQfPXgN4CREbEMQNIeZN3S39RJwYLsYRvA9mkKYCytb0vPBKaR9XVlZmYNQNIw3j1qyM3F5C02aG3XErCS5RRxlyapC/AYsA/wY7IxU96IiOa0SmEvwZvmnQJMAejWzTWIZmb1QNIMYBgwD9iQkgMoTdCSJOBRSXeSDQAGMBG4fXN5UxcfB6T3umYB/1pMoVLe6cB0yHrEKDafmZnVtEMiYvDWZt7s3VKq5hsF/A9ZdBxGNibL+cXuJCLeAP4AHAr0lNQSLMvaG7CZmdWch9IoyFul2OrBx4AXIuK8Yjecnnuti4g3JO1ANhTzd8mC16fIetSYDGx2eGUzM6sbV5MFrpfJGuy1dJg7rJjMxXaY+wzZc6nnyXrDgGwvHe4kPWibSfYy8nbADRHxLUnvJwtYuwJPAJ9Jwzd3yB3mlo77Zm1VM/2y+qC0VTMHJv9quMPc84CnaX2mRUQ8X1T+IoPW3u2lF7uTbeWgVTq+PraqmWujD0pbNXNg8q9Gg9ZDEXHo1uYvtsPcigQnMzOre09IuhaYTdsOc0va5N3MzKwUdiALVuMK0krX5N3MzKxUIuKMbclfVDdOZmZmpSCpn6RZkpal6deS+hWb30HLzMwq6efArcCeaZqd0orioGVmZpW0R0T8PCKa03QVsEexmR20zMyskpZL+oykLmn6DFl/tkWp/4YYfgdmE34Hxsyq6nPAfwPfJ7sg/RkounFGUS8XV9s2vVzsoNWGHLQ2qplT3+doWzVzYPKvFl8u3lauHjQzs4qRNDON/NGy3CsNV1IUBy0zM6ukYWnkDwAi4nXgwGIzO2iZmVklbSepV8uCpF3ZgvYV9d8Qw8zMasn3yIYmuTEtTwC+XWxmN8RoMG6I0apmTn2fo23VzIHJv1ptiJEGgRybFu+NiPnF5nX1oJlZg5I0I3WlNLcgbVdJd0t6Ln32SumSdLmkhZL+KumggjyT0/rPSZq8uf1GxPyI+FGaig5Y4KBlZtbIrgKO2STtAuCeiBgE3JOWAY4FBqVpCnAFbHwmNRUYDYwCphY+syo1By0zswYVEQ8AKzZJPpFs1HnS5ycK0q+OzMNAT0l9gPHA3RGxIrUEvJt3B8KScUMMM7P61VXSnILl6RExfTN5ekfES2n+ZaB3mu8LvFCw3pKU1lF6WThomZnVr+aIGLG1mSMiJNVUyxhXD5qZWaFXUrUf6XNZSl8K9C9Yr19K6yi9LBy0zMys0K1ASwvAycBvCtJPS60IDwHeTNWIdwLjUndMvYBxKa0sXD1oZtagJF0HHAnsLmkJWSvA7wA3SPo88DxwSlr9duA4YCGwmtQze0SskHQR8Gha71sRsWnjjtKV2S8XNxa/XNyqZk59n6Nt1cyByb9afbl4W7h60MzMcqNsQUtSf0l/kDRf0jxJ56b0dt+2NjMz25xy3mk1A/8eEYOBQ4Avpf6mOnrb2szMrFNlC1oR8VJEPJ7mVwILyF446+htazMzs05VpPWgpAFkg3z9hY7ftt40zxSy/q3o1q1bBUppZma1ruwNMSTtCPwa+EpEvFX4XWRNF9ttKhQR0yNiRESM6NrVLfPNzKzMQUvS9mQB65qIuDkld/S2tZmZWafK2XpQwM+ABRFxWcFXHb1tbWZm1qmyvVws6XDgQeBpYENK/jrZc60bgL1Ib1tv7u1pv1xcOn65uFXNvMPqc7Stmjkw+VePLxe7R4wG46DVqmZOfZ+jbdXMgcm/egxa7hHDzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzKxBSVos6WlJT0qak9J2lXS3pOfSZ6+ULkmXS1oo6a+SDqpGmR20zMwa21ERcUBEjEjLFwD3RMQg4J60DHAsMChNU4ArKl5SoGs1dmpm1hGp2iWoHRFV2e2JwJFpfiZwH3B+Sr86IgJ4WFJPSX0i4qVKFs53WmZm9aurpDkF05RNvg/gLkmPFXzXuyAQvQz0TvN9gRcK8i5JaRXlOy0zs/rVXFDt157DI2KppPcBd0t6pvDLiAhJ1bnf60DZ7rQkzZC0TNLcgrR2H/CZmVnlRcTS9LkMmAWMAl6R1AcgfS5Lqy8F+hdk75fSKqqc1YNXAcdsktbRAz4zM6sgST0k7dQyD4wD5gK3ApPTapOB36T5W4HTUivCQ4A3K/08C8pYPRgRD0gasElyRw/4zMyssnoDs5S1fOkKXBsRv5P0KHCDpM8DzwOnpPVvB44DFgKrgTMqX2RQlLF5Sgpat0XE0LT8RkT0TPMCXm9ZbifvFLJmlXTr1u3gt99+e2sLsXX56pSoqerpqqpSy6x38znahs/RVtt6jkpaHRE9SlOa2lC11oOp2WSHhyQipkfEiIgY0bWr24uYmVnlg1ZHD/jMzMw2q9JBq6MHfGZmZptVzibv1wEPAftJWpIe6n0H+Kik54Cj07KZmVlRytoQo1R69OgRq1at2rrMfsjdhh9yt6qZU9/naBs+R1u5Ica7uRsnMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLDQctMzPLjaoELUnHSPqbpIWSLqhGGczMGl0er8UVD1qSugA/Bo4FBgOTJA2udDnMzBpZXq/F1bjTGgUsjIh/RMQ7wPXAiVUoh5lZI8vltbhrFfbZF3ihYHkJMHrTlSRNAaakxZC0pgJlawCqdgEgO++aq10I1cSvwt6tZg5M1c/TEpyjO0iaU7A8PSKmp/mirsW1phpBqyjpFzt9syta7kiaExEjql0Os874PK1N1ageXAr0L1jul9LMzKxycnktrkbQehQYJGmgpG7AqcCtVSiHmVkjy+W1uOLVgxHRLOnLwJ1AF2BGRMyrdDmsqlzta3lQ1+dpXq/Fiohql8HMzKwo7hHDzMxyw0HLzMxyw0HLapqkxZJ2r3Y5zKw2OGjZNlPG55KZlZ0vNLZVJA1IHW1eDcwFfiZprqSnJU1M6xwp6baCPD+SdHqaXyzpQkmPpzz/mtJ3k3SXpHmSfkoNdY9g+SLpNEl/lfSUpF+kc/belHaPpL3SeldJukLSw5L+kc7bGZIWSLqqYHtNki5J5+bvJY2SdF/Kc0LVftAG46Bl22IQ8P+A/yJ7MXE4cDRwiaQ+ReR/LSIOAq4A/iOlTQX+GBFDgFnAXiUvtdU9SUOAbwJjI2I4cC7w38DMiBgGXANcXpClF3Ao8H/I3lX6PjAE+KCkA9I6PYB707m5ErgY+ChwEvCtcv9MlnHQsm3xfEQ8DBwOXBcR6yPiFeB+YGQR+W9On48BA9L8GOCXABHxW+D1kpbYGsVY4MaIeA0gIlaQBaVr0/e/IDtvW8yO7P2fp4FXIuLpiNgAzKP13HwH+F2afxq4PyLWpfkBWEU4aNm2WLWZ75tpe4513+T7t9Pnemq4H0xrCC3n4oaC+ZbllnNzXbS+2LpxvRTcfP5WiIOWlcKDwERJXSTtQXa39AjwPDBY0nsk9QQ+UsS2HgD+DUDSsWTVNmZb6l5ggqTdACTtCvyZrKsigE+TnbeWM/7vwEphFlnVy1NAAF+NiJcBJN1A1lBjEfBEEdu6ELhO0jyyi8w/W76QdDtwZkS8WNriW72JiHmSvg3cL2k92bl3DvBzSf8JvAqcUer9StoT+GlEHFfqbVvG3TiZmVluuHrQzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxyw0HLzMxy4/8DjnW7Wlz9gJoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((26, 23060135424), (63, 4345079040))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def matrix_mul(output, bits):\n",
    "    size = output[0] * output[1]\n",
    "    return 1, size * 1 * bits\n",
    "\n",
    "def dot_mul(output, bits):\n",
    "    return matrix_mul((output[1], 1), bits)\n",
    "\n",
    "\n",
    "### 1. KS adder can be vecotrized\n",
    "### 2. 2 Rotate to generate two random zero share is not necessary\n",
    "def MSB(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = (1 + int(np.ceil(np.log2(bits))) + 1)\n",
    "    per_comm =  (1 + 2* int(np.ceil(np.log2(bits))) + 1) * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "def Bit2AByXor(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 2\n",
    "    per_comm = 2 * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "### Currently, zeno not implemented\n",
    "### 1. One rotate can be liminated through calling 2 3PC-OT\n",
    "def Bit2AByOT(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1       # currently zeno = 2\n",
    "    per_comm = 2 * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "### a_0 * [b]^B + (a_1 + a_2) * [b]^B\n",
    "def BitMulAByOT(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1       # currently zeno = 2\n",
    "    per_comm = 4 * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "### [a]^A * Bit2AByOT([b]^B)\n",
    "def BitMulAByInjection(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1 + 1\n",
    "    per_comm = (2 + 1) * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "def relu(input, bits):\n",
    "    return MSB(input, bits)[0] + BitMulAByOT(input, bits)[0], MSB(input, bits)[1] + BitMulAByOT(input, bits)[1]\n",
    "\n",
    "# Bit2A + Mul\n",
    "def select_share(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1 + 1\n",
    "    per_comm = (2 + 1) * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "# Bit2A + Mul\n",
    "def select_share_boolean(input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1 + 1\n",
    "    per_comm = (2 + 1) * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "### Refer to Falcon\n",
    "### [a0, a1, a2, a3,]\n",
    "#  (a0 a1) (a2, a3) MSB, \n",
    "def MaxPooling(pool_size, input, bits):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    compare_count = int(np.ceil(np.log2(pool_size)))\n",
    "    per_round = compare_count * (MSB((1, 1), bits)[0] + select_share((1, 1), bits)[0])\n",
    "    per_comm = (pool_size - 1) * (MSB((1, 1), bits)[1] + select_share((1, 1), bits)[1] + pool_size * bits) # 每一轮 一次MSB, 一次select_share 乘法（max），一次 size=pool_size ANDBB（index）\n",
    "\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "def conv_complexity(input_shape, output_shape, filter_shape, bits):\n",
    "    W = output_shape[1]\n",
    "    H = output_shape[2]\n",
    "\n",
    "    f_w = filter_shape[0]\n",
    "    f_h = filter_shape[1]\n",
    "\n",
    "    c_in = input_shape[3]\n",
    "    c_out = output_shape[3]\n",
    "\n",
    "    # 1. Deduce conv --> matrix multiplication shape\n",
    "    lhs_shape_mul = (W*H, f_w*f_h*c_in)\n",
    "    rhs_shape_mul = (f_w*f_h*c_in, c_out)\n",
    "\n",
    "    res_shape = (W*H, c_out)\n",
    "\n",
    "    # 2. Matrix Mul\n",
    "    return matrix_mul(res_shape, bits)\n",
    "\n",
    "def conv_and_relu_complexity(input_shape, output_shape, filter_shape, bits):\n",
    "    W = output_shape[1]\n",
    "    H = output_shape[2]\n",
    "\n",
    "    f_w = filter_shape[0]\n",
    "    f_h = filter_shape[1]\n",
    "\n",
    "    c_in = input_shape[3]\n",
    "    c_out = output_shape[3]\n",
    "\n",
    "    # 1. Deduce conv --> matrix multiplication shape\n",
    "    lhs_shape_mul = (W*H, f_w*f_h*c_in)\n",
    "    rhs_shape_mul = (f_w*f_h*c_in, c_out)\n",
    "\n",
    "    res_shape = (W*H, c_out)\n",
    "\n",
    "    # 2. Matrix Mul + ReLU\n",
    "    # return matrix_mul(res_shape, bits) + relu(res_shape, bits)\n",
    "    return tuple_add(matrix_mul(res_shape, bits), relu(res_shape, bits))\n",
    "\n",
    "def dense_complexity(input_shape, output_shape, bits):\n",
    "    lhs_shape = input_shape[1]\n",
    "    rhs_shape = output_shape[1]\n",
    "\n",
    "    return dot_mul(output_shape, bits)\n",
    "\n",
    "def dense_relu_complexity(input_shape, output_shape, bits):\n",
    "    return tuple_add(dot_mul(output_shape, bits), relu((output_shape[1], 1), bits))\n",
    "\n",
    "def tuple_add(ta, tb):\n",
    "    l = len(ta)\n",
    "    return tuple([ta[i] + tb[i] for i in range(l)])\n",
    "\n",
    "def tuple_minus(ta, tb):\n",
    "    l = len(ta)\n",
    "    return tuple([ta[i] - tb[i] for i in range(l)])\n",
    "\n",
    "\n",
    "def Pos_share_extension(input, bits_before, bits_after):\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 3\n",
    "    per_comm = 2 * bits_before + 1 * bits_after + 1 * bits_before + 2 * bits_after\n",
    "    return per_round, per_comm * size \n",
    "\n",
    "def drop_out(input, bits):\n",
    "    # 1. Random sample random bit, with probability p = 1, (1-p) = 0\n",
    "    # 2. BitMulA in forward\n",
    "    size = input[0] * input[1]\n",
    "\n",
    "    per_round = 1       # currently zeno = 2\n",
    "    per_comm = 4 * bits\n",
    "    return per_round, per_comm * size\n",
    "\n",
    "\n",
    "# num_list1 = [1.5,0.6,7.8,6]\n",
    "# num_list2 = [1,0.3,5.5,3]\n",
    "\n",
    "# def draw_plot(num_list1, num_list2):\n",
    "#     plt.bar(range(len(num_list1)), num_list1,fc='r')\n",
    "#     plt.bar(range(len(num_list2)), num_list2,fc='g')\n",
    "#     plt.show()\n",
    "\n",
    "# draw_plot(num_list1, num_list2)\n",
    "\n",
    "verbose = False\n",
    "def main(model, bit_before, bit_after):\n",
    "    input_shape = (None, 28, 28, 1)\n",
    "    output_shape = (None, 24, 24, 16)\n",
    "\n",
    "    filter_shape = (5, 5)\n",
    "    pool_size = 2 * 2\n",
    "\n",
    "    before = conv_and_relu_complexity(input_shape, output_shape, filter_shape, bit_before)\n",
    "    after = conv_and_relu_complexity(input_shape, output_shape, filter_shape, bit_after)\n",
    "\n",
    "    print(\"Before: {0}, After: {1}\".format(before, after))\n",
    "\n",
    "    gain = (0, 0)\n",
    "    overhead = (0, 0)\n",
    "    for layer in model.layers:\n",
    "        if not verbose:\n",
    "            print(\"[{0}]{1}, {2}\".format(str(layer.name), str(layer.input_shape), str(layer.output_shape)))\n",
    "        input_shape = layer.input_shape\n",
    "        output_shape = layer.output_shape\n",
    "        if layer.name.startswith('conv2d'):\n",
    "            if not verbose:\n",
    "                print(\"------Handle convolution\")\n",
    "            gain = tuple_add(gain, tuple_minus(conv_and_relu_complexity(input_shape, output_shape, filter_shape, bit_after), conv_and_relu_complexity(input_shape, output_shape, filter_shape, bit_before)))\n",
    "\n",
    "            overhead = tuple_add(overhead, Pos_share_extension((output_shape[1] * output_shape[2], output_shape[3]), bit_before, bit_after))\n",
    "        elif layer.name.startswith('max_pooling2d'):\n",
    "            if not verbose:\n",
    "                print('------Handle max pooling')\n",
    "            in_shape = (input_shape[1]*input_shape[2], input_shape[3])\n",
    "            gain = tuple_add(gain, tuple_minus(MaxPooling(pool_size, in_shape, bit_after), MaxPooling(pool_size, in_shape, bit_before)))\n",
    "\n",
    "            overhead = tuple_add(overhead, Pos_share_extension((output_shape[1] * output_shape[2], output_shape[3]), bit_before, bit_after))\n",
    "\n",
    "        elif layer.name.startswith('dense'):\n",
    "            if not verbose:\n",
    "                print('------Handle Dense')\n",
    "            gain = tuple_add(gain, tuple_minus(dense_relu_complexity(input_shape, output_shape, bit_after), dense_relu_complexity(input_shape, output_shape, bit_before)))\n",
    "            overhead = tuple_add(overhead, Pos_share_extension((output_shape[1], 1), bit_before, bit_after))\n",
    "\n",
    "        elif layer.name.startswith('dropout'):\n",
    "            if not verbose:\n",
    "                print('------Handle Dropout')\n",
    "            gain = tuple_add(gain, tuple_minus(drop_out((input_shape[1],1), bit_after), drop_out((input_shape[1],1), bit_before)))\n",
    "            # no overhead, since only BitMulA is required for mask and gradients.\n",
    "    \n",
    "    \"\"\"\n",
    "    Plt\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax1 = fig.add_subplot()\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    name_list = ['round.', 'comm.']\n",
    "    total_width, num_para = 0.8, 2\n",
    "    width = total_width / num_para\n",
    "\n",
    "    idx = list(range(len(name_list)))\n",
    "    idx_ = list(range(len(name_list)))\n",
    "\n",
    "    for i in range(len(name_list)):\n",
    "        idx_[i] = idx_[i] + width\n",
    "\n",
    "    gain_round, gain_comm = gain\n",
    "    overhead_round, overhead_comm = overhead\n",
    "\n",
    "    ax1.bar(idx, (gain_round, overhead_round), width=width, label='gain', fc='r')\n",
    "    ax2.bar(idx_, (gain_comm * 1.0 / (1 << 23), overhead_comm * 1.0 / (1 << 23)), width=width, label='overhead', fc='b', tick_label = name_list)\n",
    "\n",
    "    ax1.set_ylabel('round')\n",
    "    ax2.set_ylabel('comm (MB)')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    return gain, overhead\n",
    "\n",
    "model = VGG16()\n",
    "main(model, 32, 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tfe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eea34229b8e7a9422a6accca9eb2232df73106413f626b426b70a8f62aaabaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
