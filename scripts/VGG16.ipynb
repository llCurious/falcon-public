{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.vgg = models.vgg16(pretrained=False)\n",
    "        \n",
    "        self.vgg.features[4] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False)\n",
    "        self.vgg.features[9] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0,  ceil_mode=False)\n",
    "        self.vgg.features[16] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0,  ceil_mode=False)\n",
    "        self.vgg.features[23] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0,  ceil_mode=False)\n",
    "        self.vgg.features[30] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0,  ceil_mode=False)\n",
    "\n",
    "        if num_classes == 10:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 10),\n",
    "            )\n",
    "        elif num_classes == 200:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.AvgPool2d(2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 200),\n",
    "            )\n",
    "        elif num_classes == 1000:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.AvgPool2d(2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(4608, 4096),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.Linear(4096, 1000)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class VGG16_Falcon(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16_Falcon, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        if num_classes == 10:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 10),\n",
    "            )\n",
    "        elif num_classes == 200:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.AvgPool2d(2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 200),\n",
    "            )\n",
    "        elif num_classes == 1000:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.AvgPool2d(2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(4608, 4096),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.Linear(4096, 1000)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch 0, Loss: 2.3094210624694824\n",
      "Epoch: 0, Batch 100, Loss: 2.297933340072632\n",
      "Epoch: 0, Batch 200, Loss: 2.304176092147827\n",
      "Epoch: 0, Batch 300, Loss: 2.304649591445923\n",
      "Epoch: 0, Batch 400, Loss: 2.3056483268737793\n",
      "Epoch: 0, Batch 500, Loss: 2.3006937503814697\n",
      "Epoch: 0, Batch 600, Loss: 2.2962560653686523\n",
      "Epoch: 0, Batch 700, Loss: 2.297899007797241\n",
      "Epoch: 0, Batch 800, Loss: 2.3032522201538086\n",
      "Epoch: 0, Batch 900, Loss: 2.302910327911377\n",
      "Epoch: 0, Batch 1000, Loss: 2.3034443855285645\n",
      "Epoch: 0, Batch 1100, Loss: 2.2999305725097656\n",
      "Epoch: 0, Batch 1200, Loss: 2.3051376342773438\n",
      "Epoch: 0, Batch 1300, Loss: 2.303309202194214\n",
      "Epoch: 0, Batch 1400, Loss: 2.300313949584961\n",
      "Epoch: 0, Batch 1500, Loss: 2.304264545440674\n",
      "Epoch: 1, Batch 0, Loss: 2.303295850753784\n",
      "Epoch: 1, Batch 100, Loss: 2.301085948944092\n",
      "Epoch: 1, Batch 200, Loss: 2.3017776012420654\n",
      "Epoch: 1, Batch 300, Loss: 2.3042843341827393\n",
      "Epoch: 1, Batch 400, Loss: 2.3008060455322266\n",
      "Epoch: 1, Batch 500, Loss: 2.304126262664795\n",
      "Epoch: 1, Batch 600, Loss: 2.302398204803467\n",
      "Epoch: 1, Batch 700, Loss: 2.306032657623291\n",
      "Epoch: 1, Batch 800, Loss: 2.3029627799987793\n",
      "Epoch: 1, Batch 900, Loss: 2.303208112716675\n",
      "Epoch: 1, Batch 1000, Loss: 2.3041911125183105\n",
      "Epoch: 1, Batch 1100, Loss: 2.302325487136841\n",
      "Epoch: 1, Batch 1200, Loss: 2.30220103263855\n",
      "Epoch: 1, Batch 1300, Loss: 2.307149887084961\n",
      "Epoch: 1, Batch 1400, Loss: 2.3032076358795166\n",
      "Epoch: 1, Batch 1500, Loss: 2.3010048866271973\n",
      "Epoch: 2, Batch 0, Loss: 2.3028714656829834\n",
      "Epoch: 2, Batch 100, Loss: 2.301422595977783\n",
      "Epoch: 2, Batch 200, Loss: 2.2998790740966797\n",
      "Epoch: 2, Batch 300, Loss: 2.3029022216796875\n",
      "Epoch: 2, Batch 400, Loss: 2.301372528076172\n",
      "Epoch: 2, Batch 500, Loss: 2.3048665523529053\n",
      "Epoch: 2, Batch 600, Loss: 2.301272392272949\n",
      "Epoch: 2, Batch 700, Loss: 2.2995693683624268\n",
      "Epoch: 2, Batch 800, Loss: 2.3027377128601074\n",
      "Epoch: 2, Batch 900, Loss: 2.303652286529541\n",
      "Epoch: 2, Batch 1000, Loss: 2.304652214050293\n",
      "Epoch: 2, Batch 1100, Loss: 2.300554037094116\n",
      "Epoch: 2, Batch 1200, Loss: 2.3012328147888184\n",
      "Epoch: 2, Batch 1300, Loss: 2.3039064407348633\n",
      "Epoch: 2, Batch 1400, Loss: 2.3018054962158203\n",
      "Epoch: 2, Batch 1500, Loss: 2.3036246299743652\n",
      "Epoch: 3, Batch 0, Loss: 2.304886817932129\n",
      "Epoch: 3, Batch 100, Loss: 2.302375555038452\n",
      "Epoch: 3, Batch 200, Loss: 2.300593137741089\n",
      "Epoch: 3, Batch 300, Loss: 2.3036396503448486\n",
      "Epoch: 3, Batch 400, Loss: 2.308330535888672\n",
      "Epoch: 3, Batch 500, Loss: 2.3027374744415283\n",
      "Epoch: 3, Batch 600, Loss: 2.300783157348633\n",
      "Epoch: 3, Batch 700, Loss: 2.2955496311187744\n",
      "Epoch: 3, Batch 800, Loss: 2.3027899265289307\n",
      "Epoch: 3, Batch 900, Loss: 2.302305221557617\n",
      "Epoch: 3, Batch 1000, Loss: 2.304854154586792\n",
      "Epoch: 3, Batch 1100, Loss: 2.302621841430664\n",
      "Epoch: 3, Batch 1200, Loss: 2.3021397590637207\n",
      "Epoch: 3, Batch 1300, Loss: 2.3045828342437744\n",
      "Epoch: 3, Batch 1400, Loss: 2.3057239055633545\n",
      "Epoch: 3, Batch 1500, Loss: 2.304276943206787\n",
      "Epoch: 4, Batch 0, Loss: 2.3028528690338135\n",
      "Epoch: 4, Batch 100, Loss: 2.301762580871582\n",
      "Epoch: 4, Batch 200, Loss: 2.304373025894165\n",
      "Epoch: 4, Batch 300, Loss: 2.2994041442871094\n",
      "Epoch: 4, Batch 400, Loss: 2.303619861602783\n",
      "Epoch: 4, Batch 500, Loss: 2.301020383834839\n",
      "Epoch: 4, Batch 600, Loss: 2.3049967288970947\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "logger = SummaryWriter(log_dir = 'log')\n",
    "\n",
    "\n",
    "model = VGG16_Falcon()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "# VGG16 CryptGPU\n",
    "# lr=0.001, momentum=0.9 converges about 2~3 epoch. Without momentum, it does not converge.\n",
    "# lr=0.01 (remove Dropout) converges about 3~4 epoch.\n",
    "\n",
    "# VGG16 Official\n",
    "# lr=0.01 \n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "it = 10\n",
    "for epoch in range(it):\n",
    "    for batch, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "        output = model(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch: {}, Batch {}, Loss: {}'.format(epoch, batch, loss.item()))\n",
    "\n",
    "output = model(images)\n",
    "_, output = torch.max(output, 1)\n",
    "print(f\"Output: ${output}\")\n",
    "print(f\"Target: ${labels}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8e35784da7b5309346b9948007e2c8e432cfca57e220859a198433798687959"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
